---
title: S3
slug: /tech/devops/aws/basic/S3
tags: [AWS,"S3"]
date: 2024-01-31T01:45
---
# S3(Simple Storage Service)

## S3基础知识

### 什么是S3

Amazon **Simple Storage Service (S3)** 是互联网存储解决方案，它提供了一个简单的Web接口，让其存储的数据和文件在互联网的任何

地方给任何人访问，可用于数据湖，网站，移动应用程序，备份和恢复，归档，企业应用程序，IoT设备和大数据分析

Amazon S3的服务给开发人员提供了高扩展性、可靠性、安全性和快速廉价的数据存储基础架构，Amazon.com网站上的内容也运行在S3上

### S3可以用来做什么

- 备份
- 数据湖
  - 汇总数据
  - 分析数据
  - 简化数据湖管理
  - 机器学习

### 特点

- 持久性、弹性和可用性
- 安全合规和审计能力
- 对象级别的权限控制及成本节约
- 在你的数据中挖掘商业价值
- 支持多种方式将数据搬上云

### 特性

- S3是**对象存储**，可以在S3上存储各种类型的文件，它不是**块存储**（EBS是块存储）
- 文件大小可以从0 字节到5 TB
  - 使用Single Operation上传只能上传最大5 GB的文件
  - 使用分段上传（Multipart Upload）可以对文件进行分段上传，最大支持上传5 TB的文件
- S3的总存储空间是**无限大**的
- 文件存储在**存储桶（Bucket）**内，可以理解存储桶就是一个文件夹
- S3的名字是需要**全球唯一**的，不能与任何区域的任何人拥有的S3重名
- 存储桶创建之后会生成一个URL，命名类似于 https://iteablue.s3.ap-northeast-1.amazonaws.com/abc/puppy.jpg
  - S3是以HTTPS的形式展现的，而非HTTP
  - ap-northeast-1表示了当前桶所在的区域
  - iteablue表示了S3存储桶的名字，全球唯一
- S3的存储桶创建的时候可以选择所在区域（Region），但不能选择可用区（AZ），AWS会负责S3的高可用、容灾问题
  - S3创建的时候可以选择某个AWS区域，一旦选择了**就不能更改**
  - 如果要在其他区域使用该S3的内容，可以使用**跨区域复制**
- S3拥有不同的类型（Standard, Stantard-IA, Intelligent Tiering, Onezone-IA, RRS, Glacier等）
- 启用了**版本控制（Version Control）**你可以恢复S3内的文件到之前的版本
- S3可以开启生命周期管理，对文件在不同的生命周期进行不同的操作
  - 比如，文件在创建30天后迁移到便宜的S3等级（S3-IA），再经过30天进行归档（迁移到Glacier），再过30天就进行删除
- S3支持加密功能
- 使用访问控制列表（Access Control Lists）和桶策略（Bucket Policy）可以控制S3的访问安全
- 在S3上成功上传了文件，你将会得到一个**HTTP 200**的状态反馈'

### S3的限制

1. Amazon S3 存储桶归创建它的 AWS 账户 所有。存储桶所有权不可转移到其他账户
2. 创建存储桶后，便无法再更改其名称或区域
3. 没有最大存储桶大小，对存储桶中可存储的项目数也没有限制。您可以在单个存储桶中存储所有对象，也可以在多个存储桶中组织它们。但是，您无法从其他存储桶中创建存储桶

### Key-Value store

S3是基于对象的，每一个对象包括了这些参数

- **键（Key）**：可以认为是数据的名字
- **值（Value）**：表示数据本身
- **版本号（Version ID）**：对于启用了版本控制的存储桶来说很重要
- **元数据（Metadata）**：关于数据的描述，比如说数据的创建时间，更改时间，文件类型，文件大小等信息
- **访问控制信息**：能管理对Bucket内文件的访问权限

### 什么是持久性、可用性

持久性：数据不会丢

可用性：服务不会挂

![image-20230320192503955](https://picgo-starry.oss-cn-beijing.aliyuncs.com/img/devops/AWS/s3-durability.png)

### 功能

- 管理
  - S3 object tagging
  - S3 prefixes
- 监控
  - CloudWatch
  - CloudTrail
  - S3 event notifications
  - S3 Inventory
  - S3 storage class analysis
  - S3 Glacier restore notifications
- 同步和数据分级
  - Cross-region repliaction
  - S3 lifecycle
  - EBS data lifecycle manager
  - Cross-region replication
  - Direct PUT to S3 Glacier
- 数据更新
  - S3 event notifications + Lambda
  - S3 Glacier restore speed upgrade
  - S3 object lock
  - S3 batch operations

### S3的收费标准

- 存储费用
  - 按每GB的存储收费，存储内容越多，综合单价越便宜
- 请求
  - S3的PUT, COPY, POST或LIST等请求也需要按请求数收费
  - DELETE请求不收费
- 存储管理费用
  - 包括了S3清单，S3分析和S3对象标记功能的费用
- 数据传输费用
  - 包括S3通过互联网传入和传出的费用，在同一个区域，S3存储桶之间或从S3传输到其他AWS服务均不收费
- 传输加速费用
  - Transfer Acceleration 定价要加到数据传输定价上

## S3 存储类别

[存储类别比较](https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/userguide/storage-class-intro.html#sc-compare)

![image-20230320194555917](https://picgo-starry.oss-cn-beijing.aliyuncs.com/img/devops/AWS/s3-storge-type.png)

|           | S3 Glacier Flexible Retrieval | S3 Glacier Deep Archive |
| --------- | ----------------------------- | ----------------------- |
| Expedited | 1-5分钟                       | N/A                     |
| Standard  | 3-5小时                       | 12小时内                |
| Bulk      | 5-12小时                      | 24小时内                |

![image-20230320195936445](https://picgo-starry.oss-cn-beijing.aliyuncs.com/img/devops/AWS/S3-intelligent-tiering.png)

###  S3 Express One Zone

Amazon S3 Express One Zone 是高性能的单区 Amazon S3 存储类，专门用于为延迟要求极高的应用程序提供稳定的毫秒级数据访问。S3 Express One Zone 是目前具有极低延迟的云对象存储类，相比 S3 Standard，其数据访问速度要快 10 倍，且请求成本低 50%。请求的完成速度实现了数量级的提升，应用程序可以直接从中获益。S3 Express One Zone 提供与其它 S3 存储类相似的性能弹性。

![image-20240330112025193](https://picgo-starry.oss-cn-beijing.aliyuncs.com/img/note/tech/image-20240330112025193.png)

## S3 版本控制

- 启用版本控制后S3会保存一个文件的所有版本，包括所有历史写入的版本，即使删除了的文件也会保存
- 版本控制是很好的备份工具
- 启用了版本控制功能之后，要恢复一个文件，只需要删除**删除标记（Delete Marker）**即可
- 版本控制默认不开启，但**一旦启用，就不能关闭**，只能暂停
- 版本控制一经开启，所有在这个S3桶内的对象都会受用
- 版本控制可以和生命周期规则集成使用
- 使用**MFA (Multi-Factor Authentication，多重认证) Delete**可以在删除文件的时候增加多一层安全保障，防止用户进行误删除操作
- 因为S3版本控制保存了一个文件对象的所有版本，每一个版本都会相应进行收费，因此费用会比不启用版本控制的S3桶要高
  - 举个例子，如果一个1 MB的文件有5个历史版本，那么你将会被收取等同于5 MB的单一文件的费用

## 跨区域控制

### 不同场景

- 在同一AWS区域内同步数据
- 将数据同步到另一个AWS区域的一个或多个桶
- 同步到一个有生命周期管理的桶上
- 双向复制

### 同区域复制

- ﻿将日志聚合到单个存储桶一如果您在多个存储桶中或者跨多个账户存储日志，则可以轻松地将日志复制到区域中的单个存储桶。这样

  做实现了在单个位置更简单地处理日志。

- ﻿在生产账户和测试账户之间配置实时复制一如果您或您的容户有使用相同数据的生产账户和测试账户，您可以在那些账户之间复制对

  象，同时保留对象元数据

- 遵守数据主权法律一您可能需要将数据的多个副本存储在特定区域内的单独 AWS 账户 中。当合规性法规不允许数据离开您的国家/地

  区时，同区域复制可帮助您自动复制关键数据。

### 跨区域复制

- ﻿满足合规性要求一虽然 Amazon S3 默认跨多个地理位置较远的可用区存储数据，但是合规性要求所规定的数据存储距离可能更远。

  为满足这些要求，可以使用跨区域复制在远距离 AWS区域之间复制数据。

- ﻿最大限度减少延迟一 如果客户处于两个地理位置，您可以在地理位置与用户较近的AWS 区域中维护对象副本，从而最大限度缩短访

  问对象时的延迟。

- ﻿﻿提高操作效率一如果您在两个不同 AWs 区域中具有分析同一组对象的计算集群，则可以选择在这些区域中维护对象副本。

### 数据同步的时间保证

S3 RTC确保99.99%的数据会在15分钟内同步完成

## 生命周期管理

- 可以对文件当前的版本和历史版本进行生命周期管理
- 生命周期管理可以做到（X，Y，Z为自定义天数）
  - （转换操作）在文件创建的X天后将文件移动到**Standard – IA (Infrequently Accessed)**
  - （转换操作）再过Y天将文件移动到**Glacier**
  - （过期操作）再过Z天将文件永久删除

### 不支持的转换类型

- 从任何存储类转换为 S3 Standard 存储类。
- 任何存储类转换为低冗余存储 (RRS) 类。
- 从 S3 Intelligent-Tiering 存储类转换为 S3 Standard-IA 存储类。
- 从 S3 One Zone-IA 存储类转换为 S3 Intelligent-Tiering、S3 Standard-IA 或 S3 Glacier Instant Retrieval 存储类。

### 转换约束

生命周期存储类转换具有以下约束：

当您将对象从 S3 Standard 或 S3 Standard-IA 存储类转换为 S3 Intelligent-Tiering 、S3 Standard-IA 或 S3 One Zone-IA 时，将应用以下对象大小约束：

- **较大的对象** – 对于以下转换，转换较大对象具有成本效益：
  - 从 S3 Standard 或 S3 Standard-IA 存储类转换为 S3 Intelligent-Tiering。
  - 从 S3 Standard 存储类转换为 S3 Standard-IA 或 S3 One Zone-IA。
- **小于 128KiB 的对象** – 对于以下转换，Amazon S3 不转换小于 128KiB 的对象：
  - 从 S3 Standard 或 S3 Standard-IA 存储类转换为 S3 Intelligent-Tiering 或 S3 Glacier Instant Retrieval。
  - 从 S3 Standard 存储类转换为 S3 Standard-IA 或 S3 One Zone-IA。

## S3安全和加密选项

### 最佳实践

1. ﻿﻿确保您的 Amazon S3存储桶使用正确的策略且不可公有访问，实施最低权限访问
   1. 限制桶的公开访问权限
   2. 保证存储桶策略没有过大的权限，比如通配符操作
   3. ACL
2. ﻿﻿将IAM 角色用于需要 Amazon S3 访问权限的应用程序和 AWS 服务
3. ﻿﻿﻿考虑加密静态数据
4. ﻿﻿﻿实施传输中数据加密
   1. 服务端加密：
      1. SSE-S3(Amazon托管密钥)： 使用256位AES-256加密标准进行加密，并且主密钥会定期轮换
      2. SSE-KMS： 使用AWS提供的密钥管理系统，有更多的密钥管理能力
      3. SSE-C(客户端提供密钥) ：**–** 你来提供和管理加密密钥，S3负责加密和解密
   2. 客户端加密
      1. Encryption SDK加密
5. ﻿﻿﻿考虑S3 对象锁定(一次写入，多次读取)

6. 考虑使用 VPC 端点进行 Amazon S3 访问
7. 启动版本控制
8. 考虑跨区域复制

## S3访问点

针对不同使用S3的团队，配置不同的访问点，基于访问点指定策略

Amazon S3 接入点简化了在 S3 中存储数据的任何AWS服务或客户应用程序的数据访问。接入点是附加到存储桶的命名网络端点，您可以使用这些存储桶执行 S3 对象操作（如 `GetObject` 和 `PutObject`）。每个接入点都具有不同的权限和网络控制，S3 将它们应用于通过该接入点发出的任何请求。每个接入点强制实施自定义接入点策略

**使用场景**

![image-20240323153853327](https://picgo-starry.oss-cn-beijing.aliyuncs.com/img/note/tech/image-20240323153853327-20240323154118209.png)

在这种场景下，如果我们使用S3 policy去控制访问，就会很繁琐. 

所以我们可以使用访问点去控制访问.

### 单区域访问点

**创建和使用一个访问点的步骤**

[Video](https://www.youtube.com/watch?v=Mqo4rt12IL0&ab_channel=MahendraPandey)

1. 创建一个IAM policy可以访问S3的访问点以及可以List相应的S3 bucket. 

2. 创建一个user,并赋予1步骤所创建的策略

3. 创建一个S3, 并赋予policy可以让相应的user访问对应的资源，可以设置只允许通过访问点访问.

   ![image-20240323154713427](https://picgo-starry.oss-cn-beijing.aliyuncs.com/img/note/tech/image-20240323154713427.png)

4. 创建一个访问点, name 为datauser1-ap，并赋予访问点相应的策略. dataset1为这个S3下的目录

   ![image-20240323154911236](https://picgo-starry.oss-cn-beijing.aliyuncs.com/img/note/tech/image-20240323154911236.png)

#### 限制和局限性

[限制](https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/userguide/access-points-restrictions-limitations.html)

### 多区域访问点

[Video](https://www.youtube.com/watch?v=UUleX4pXLVo&ab_channel=LearnCantrill)

#### 作用

1. 跨地域数据复制：多区域访问点允许您在不同 AWS 区域之间复制 S3 存储桶的数据。您可以在源存储桶和目标存储桶之间设置复制策略，实现数据的自动跨区域复制，确保数据的冗余性和可用性。可以实现多个S3同步.
2. 数据流量控制和成本优化：多区域访问点允许您为每个访问点配置数据传输控制策略和配额限制。您可以根据需求调整每个访问点的并发连接数、吞吐量和数据传输费用，以满足应用程序的需求并优化成本。
3. 简化应用程序开发：通过多区域访问点，您可以使用统一的访问接口和终端节点来访问跨多个区域的 S3 存储桶。这简化了应用程序的开发和维护过程，无需为每个区域单独管理访问接口和终端节点。
4. 跨区域数据访问：通过多区域访问点，您可以在多个 AWS 区域之间更快地访问 S3 存储桶的数据。AWS 会自动为每个区域创建一个访问点，并为每个访问点分配唯一的终端节点。这样一来，您可以使用就近的访问点来加速数据的读取和写入操作，减少访问延迟

## S3 传输加速

一般来说，我们在上传文件到S3存储桶的时候，是直接通过Internet将数据传输到位于某一个区域的S3存储桶。但如果我们的存储桶位于

一个离用户比较远的区域（比如说S3存储桶位于东京区域，而我们的用户位于中国），那么基于Internet的传输速度就会非常慢。

这个时候使用**S3传输加速 （Amazon S3 Transfer Acceleration）**，可以利用AWS CloudFront CDN网络的**边缘节点（Edge **

**Locations）**加速传输的过程。我们可以将数据上传到离我们最近的边缘节点（比如说香港），然后再通过AWS内部网络（更高速，更稳

定）传输到东京区域的S3存储桶。

在以下情形下你可能就需要考虑使用S3传输加速：

- 您位于全球各地的客户需要上传到集中式存储桶
- 您定期跨大洲传输数 GB 至数 TB 数据
- 您在上传到 Amazon S3 时未充分利用 Internet 上的可用带宽

### 使用分段上传

如果对象大小达到了100MB,则推荐使用分段上传(控制台不支持)

**优势：**

- 提高吞吐量，可以并行上传
- 从任何网络问题中快速恢复
- 暂停和恢复上传，没有过期期限
- 可以在创建对象时上传，边生成边上传

测试链接：https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html

## S3性能调优

### 前缀

前缀是对象键名称开头的一串字符串。可以把前缀视为一种以类似于目录的方式组织数据的方式。但是，前缀不是目录。

按前缀搜索会将结果限制为仅以指定前缀开头的这些键。分隔符导致列表操作将共享公共前缀的所有键汇总到单个汇总列表结果中。

- 当从 Amazon S3 上传和检索存储时，您的应用程序可以轻松地实现每秒数千个事务的请求性能。Amazon S3 自动扩展到高请求速

  率。例如，您的应用程序可以实现至少每秒每个已分区前级 3500个PUT/COPY/POST/DELETE 请求或5500 个 GET/HEAD 请求。对存

  储桶中的前缀数量没有限制。可以通过使用并行来增加读取或写入性能。

- 可以在S3中创建多个前缀，比如创建10个，就可以每秒处理55000个请求

### 字节范围提取

通过在 GET Object 请求中使用 Range HTTP 标头，您可以从对象中提取字节范围，而只传输指定的部分。可以使用到 

Amazon S3 的并行连接，从相同对象中提取不同的字节范国。这有助于您通过单一整个对象请求实现更高的聚合吞吐量。通过提取

较小范围的大型对象，您的应用程序还可以在请求中断时改善重试次数

### 使用S3传输加速

使用 Amazon S3 Transfer Acceleration 配置快速、安全的文件传输 可在客户端与 S3 存储桶之间管理快速、轻松和安全的长地理距离文

件传输。Transfer Acceleration 利用 Amazon CloudFront 中的全球分布式边缘站点。当数据到达某个边缘站点时，会通过经过优化的网

络路径路由至 Amazon S3.Transfer Acceleration 适合定期跨大洲传输 GB 到TB 的数据。它也适用于全球各地需要上传到集中式存储桶

的客户

## S3静态托管网站

- 不需要服务器费用
- S3不支持动态网站
- 两种域名方式:
  - s3-websit(-). : httpL//bucket-name.s2-website- Region.***
  - S2-website(.):httpL//bucket-name.s2-website.Region
- S3不支持HTTPS,如果要使用，可以使用CloudFront

## Transfer Acceleration

Amazon S3 Transfer Acceleration 是一项存储桶级别功能，可在您的客户端和 S3 存储桶之间实现快速、轻松、安全的远距离文件传输。Transfer Acceleration 旨在优化从世界各地传入 S3 存储桶的传输速度。Transfer Acceleration 利用 Amazon CloudFront 中的全球分布式边缘站点。当数据到达某个边缘站点时，数据会被经过优化的网络路径路由至 Amazon S3

### 适用情况

- 您位于全球各地的客户需要上载到集中式存储桶。
- 您定期跨大洲传输数 GB 至数 TB 数据。
- 您在上载到 Amazon S3 时无法充分利用 Internet 上的所有可用带宽。

### 怎么使用

开启前访问S3 object通过`mybucket.s3.us-east-1.amazonaws.com` 

开启后访问S3 object通过`mybucket.s3-accelerate.amazonaws.com`

### 不支持的操作

- [GET 服务（列出存储桶）](https://docs.aws.amazon.com/AmazonS3/latest/API/RESTServiceGET.html)
- [PUT Bucket（创建存储桶）](https://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketPUT.html)
- [DELETE Bucket](https://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketDELETE.html)

此外，Amazon S3 Transfer Acceleration 不支持使用 [PUT Object - Copy](https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectCOPY.html) 进行跨区域复制。

### 速度比较工具

 [Amazon S3 Transfer Acceleration 速度比较工具](https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html)

将以下 URL 复制到浏览器窗口中，并分别将 `region` 和 `yourBucketName` 替换为您使用的 AWS 区域（例如 `us-west-2`）和要评估的存储桶的名称：https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html?region=region&origBucketName=yourBucketName